{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "845f9409",
   "metadata": {},
   "source": [
    "# case study group 23\n",
    "\n",
    "> You are an employee of a fictitious company “106”, which sells gearshift systems to car manufacturers. In order to improve the product of the automatic gearshift system “K3AG1”, your company plans to analyze the damage cases of the last years. The automatic gearshift “K3AG1” is a standard component of the car brand “OEM1” and can be selected by the customer as an equipment feature of the car types “Type11” or “Type12”. From the management of your department you get the task to analyze the production data and parts lists of the customer and your suppliers. Key performance indicators such as service life, mileage, failure rates and usage data are of great importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803613db",
   "metadata": {},
   "source": [
    "## 1. Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f863559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_csv_auto(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read CSV with automatic delimiter detection and robust date parsing off (we'll parse later).\"\"\"\n",
    "    df = pd.read_csv(path, sep=None, engine=\"python\", dtype=str)\n",
    "    # Drop typical unnamed index columns, if any\n",
    "    df = df.loc[:, ~df.columns.str.contains(r\"^Unnamed\", case=False)]\n",
    "    # Strip quotes/spaces from column names\n",
    "    df.columns = df.columns.str.strip().str.replace('\"', '', regex=False)\n",
    "    # Strip surrounding quotes/spaces from string cells\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = df[col].map(lambda x: x.strip().strip('\"') if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "# Vehicles (baseline)\n",
    "path_typ11 = \"data/Fahrzeug/Fahrzeuge_OEM1_Typ11.csv\"\n",
    "path_typ12 = \"data/Fahrzeug/Fahrzeuge_OEM1_Typ12.csv\"\n",
    "\n",
    "# Registrations\n",
    "# path_reg   = \"source/Zulassungen/Zulassungen_alle_Fahrzeuge.csv\"\n",
    "\n",
    "# Parts per vehicle\n",
    "path_parts11 = \"data/Fahrzeug/Bestandteile_Fahrzeuge_OEM1_Typ11.csv\"\n",
    "path_parts12 = \"data/Fahrzeug/Bestandteile_Fahrzeuge_OEM1_Typ12.csv\"\n",
    "\n",
    "# Component (K3AG1)\n",
    "path_k3ag1   = \"data/Komponente/Komponente_K3AG1.csv\"\n",
    "# path_k3AG1_parts = \"Bestandteile_Komponente_K3AG1.csv\"\n",
    "\n",
    "# Component (K3SG1)\n",
    "path_k3sg1 = \"data/Komponente/Komponente_K3SG1.csv\"\n",
    "\n",
    "df_typ11  = read_csv_auto(path_typ11)\n",
    "df_typ12  = read_csv_auto(path_typ12)\n",
    "# df_reg    = read_csv_auto(path_reg)\n",
    "df_parts11 = read_csv_auto(path_parts11)\n",
    "df_parts12 = read_csv_auto(path_parts12)\n",
    "df_k3ag1  = read_csv_auto(path_k3ag1)\n",
    "df_k3sg1 = read_csv_auto(path_k3sg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2fcf41",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed1531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coalesce_first(df: pd.DataFrame, candidates: List[str], new_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create/overwrite df[new_name] with the first existing, non-null column among candidates.\n",
    "    If none exist, the column is created with NaN.\n",
    "    \"\"\"\n",
    "    values = None\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            values = df[c] if values is None else values.fillna(df[c])\n",
    "    df[new_name] = values if values is not None else np.nan\n",
    "    return df\n",
    "\n",
    "# Vehicles: ensure presence of the vehicle ID column name 'ID_Fahrzeug'\n",
    "# (Some exports may have it quoted; read_csv_auto already strips quotes.)\n",
    "if \"ID_Fahrzeug\" not in df_typ11.columns:\n",
    "    # Attempt to find a close match; fallback to no-op if absent.\n",
    "    pass\n",
    "if \"ID_Fahrzeug\" not in df_typ12.columns:\n",
    "    pass\n",
    "\n",
    "# Tag vehicle type for provenance\n",
    "if len(df_typ11):\n",
    "    df_typ11[\"vehicle_type\"] = \"Typ11\"\n",
    "if len(df_typ12):\n",
    "    df_typ12[\"vehicle_type\"] = \"Typ12\"\n",
    "\n",
    "# Baseline vehicles: stack, keep all columns; align by column name\n",
    "df_vehicles_base = pd.concat([df_typ11, df_typ12], ignore_index=True, sort=False)\n",
    "\n",
    "# Parts: unify the two parts tables and keep the shared columns\n",
    "# Expected keys include: ID_Karosserie, ID_Schaltung, ID_Sitze, ID_Motor, ID_Fahrzeug\n",
    "df_parts_all = pd.concat([df_parts11, df_parts12], ignore_index=True, sort=False)\n",
    "\n",
    "# Registrations: standardize join key name to 'ID_Fahrzeug' and rename to English labels\n",
    "# Some files name the vehicle ID as 'IDNummer'\n",
    "# if \"IDNummer\" in df_reg.columns and \"ID_Fahrzeug\" not in df_reg.columns:\n",
    "#     df_reg = df_reg.rename(columns={\"IDNummer\": \"ID_Fahrzeug\"})\n",
    "# df_reg = df_reg.rename(columns={\n",
    "#     \"Gemeinden\": \"registration_municipality\",\n",
    "#     \"Zulassung\": \"registration_date\",\n",
    "# })\n",
    "\n",
    "def clean_k3_dataframe(df):\n",
    "    df = coalesce_first(\n",
    "        df,\n",
    "        candidates=[\"ID_Schaltung\", \"ID_Schaltung.x\", \"ID_Schaltung.y\"],\n",
    "        new_name=\"ID_Schaltung\"\n",
    "    )   \n",
    "    \n",
    "    df = coalesce_first(df,\n",
    "        [\"Produktionsdatum\", \"Produktionsdatum.x\", \"Produktionsdatum.y\"],\n",
    "        \"transmission_production_date\"\n",
    "    )\n",
    "    df = coalesce_first(df,\n",
    "        [\"Herstellernummer\", \"Herstellernummer.x\", \"Herstellernummer.y\"],\n",
    "        \"transmission_manufacturer_no\"\n",
    "    )\n",
    "    df = coalesce_first(df,\n",
    "        [\"Werksnummer\", \"Werksnummer.x\", \"Werksnummer.y\"],\n",
    "        \"transmission_plant_no\"\n",
    "    )\n",
    "    df = coalesce_first(df,\n",
    "        [\"Fehlerhaft\", \"Fehlerhaft.x\", \"Fehlerhaft.y\"],\n",
    "        \"transmission_defective_flag\"\n",
    "    )\n",
    "    df = coalesce_first(df,\n",
    "        [\"Fehlerhaft_Datum\", \"Fehlerhaft_Datum.x\", \"Fehlerhaft_Datum.y\"],\n",
    "        \"transmission_defective_date\"\n",
    "    )\n",
    "    df = coalesce_first(df,\n",
    "        [\"Fehlerhaft_Fahrleistung\", \"Fehlerhaft_Fahrleistung.x\", \"Fehlerhaft_Fahrleistung.y\"],\n",
    "        \"transmission_defective_mileage\"\n",
    "    )\n",
    "\n",
    "    # Keep only the columns we standardized plus the join key\n",
    "    keep_cols_k3 = [\n",
    "        \"ID_Schaltung\",\n",
    "        \"transmission_production_date\",\n",
    "        \"transmission_manufacturer_no\",\n",
    "        \"transmission_plant_no\",\n",
    "        \"transmission_defective_flag\",\n",
    "        \"transmission_defective_date\",\n",
    "        \"transmission_defective_mileage\",\n",
    "    ]\n",
    "\n",
    "    keep_cols_k3 = [c for c in keep_cols_k3 if c in df.columns]\n",
    "    df = df[keep_cols_k3].drop_duplicates()\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "df_k3 = pd.concat([df_k3ag1, df_k3sg1], axis = 0, ignore_index=True)\n",
    "df_k3 = clean_k3_dataframe(df_k3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444b200",
   "metadata": {},
   "source": [
    "## 3. Creation of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea49c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with parts (by vehicle)\n",
    "df_merged = df_vehicles_base.merge(\n",
    "    df_parts_all,\n",
    "    how=\"left\",\n",
    "    on=\"ID_Fahrzeug\",\n",
    "    suffixes=(\"\", \"_parts\"),\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "\n",
    "# Merge with K3AG1/K3SG1 component (by transmission ID from parts)\n",
    "df_merged = df_merged.merge(\n",
    "    df_k3,\n",
    "    how=\"left\",\n",
    "    on=\"ID_Schaltung\",\n",
    "    validate=\"m:1\"\n",
    ")\n",
    "\n",
    "rename_map = {\n",
    "    \"ID_Fahrzeug\": \"vehicle_id\",\n",
    "    \"Produktionsdatum\": \"vehicle_production_date\",\n",
    "    \"Herstellernummer\": \"vehicle_manufacturer_no\",\n",
    "    \"Werksnummer\": \"vehicle_plant_no\",\n",
    "    \"Fehlerhaft\": \"vehicle_defective_flag\",\n",
    "    \"Fehlerhaft_Datum\": \"vehicle_defective_date\",\n",
    "    \"Fehlerhaft_Fahrleistung\": \"vehicle_defective_mileage\",\n",
    "    \"ID_Schaltung\": \"transmission_id\"\n",
    "}\n",
    "\n",
    "df_merged = df_merged.rename(columns=rename_map)\n",
    "\n",
    "date_like_cols = [c for c in [\n",
    "    \"registration_date\",\n",
    "    \"transmission_production_date\",\n",
    "    \"transmission_defective_date\",\n",
    "] if c in df_merged.columns]\n",
    "\n",
    "for c in date_like_cols:\n",
    "    try:\n",
    "        parsed = pd.to_datetime(df_merged[c], errors=\"coerce\")\n",
    "        # Keep ISO-8601 string for portability\n",
    "        df_merged[c] = parsed.dt.strftime(\"%Y-%m-%d\")\n",
    "    except Exception:\n",
    "        # Leave as-is on any parsing issues\n",
    "        pass\n",
    "\n",
    "df_keeps = df_merged[[ \n",
    "    'vehicle_id', \n",
    "    'vehicle_production_date',\n",
    "    'transmission_id', \n",
    "    'transmission_production_date',  'transmission_defective_flag',\n",
    "    'transmission_defective_date', 'transmission_defective_mileage']]\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_path = \"Final_dataset_group_23.csv\"\n",
    "\n",
    "# Write CSV (UTF-8, comma delimiter, English-friendly headers we added remain in English)\n",
    "df_keeps.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "df_keeps.to_csv(f\"{output_path}.gz\", index=False, compression=\"gzip\")   # gzip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7571dc",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd7558",
   "metadata": {},
   "source": [
    "## 5. Result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
